name: Deploy a workflow in Source Account to process and send data

on:
 workflow_dispatch:
 push:
    branches:
      - main
    paths:
      # This workflow ONLY triggers automatically if these specific files change
      - 'requirements.txt'
      
permissions:
      id-token: write   # This is required for requesting the JWT
      contents: read 

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
         role-to-assume: arn:aws:iam::${{ secrets.ACCOUNT_ID }}:role/${{ secrets.ROLE_NAME }}
         aws-region: ${{ secrets.REGION }}

    - name: Check CloudFormation stack status for EMR and S3
      id: check_status
      run: |
        STACK_NAME="MyEMRS3"
        STACK_STATUS=$(aws cloudformation describe-stacks --stack-name $STACK_NAME --query "Stacks[0].StackStatus" --output text 2>&1 || echo "STACK_DOES_NOT_EXIST")
        if [[ "$STACK_STATUS" == "STACK_DOES_NOT_EXIST" ]]; then
          echo "Stack $STACK_NAME does not exist."
          echo "::set-output name=status::NOT_FOUND"
        else
          echo "Stack status for EMR and S3: $STACK_STATUS"
          echo "::set-output name=status::$STACK_STATUS"
        fi

    # - name: Delete CloudFormation stack EMR and S3
    #   if: steps.check_status.outputs.status != 'CREATE_COMPLETE' && steps.check_status.outputs.status != 'NOT_FOUND'
    #   run: |
    #     echo "Deleting stack MyEMRS3 because status is ${{ steps.check_status.outputs.status }}"
    #     aws cloudformation delete-stack --stack-name MyEMRS3
    #     aws cloudformation wait stack-delete-complete --stack-name MyEMRS3
 
    - name: Deploy EMR and S3 using CloudFormation
      if: steps.check_status.outputs.status != 'CREATE_COMPLETE' && steps.check_status.outputs.status != 'NOT_FOUND'
      run: |
        aws cloudformation deploy \
          --template-file cloudformation/EMR_S3.yaml \
          --stack-name MyEMRS3 \
          --capabilities CAPABILITY_NAMED_IAM
        aws cloudformation wait stack-create-complete --stack-name MyEMRS3

    - name: Check CloudFormation stack status for Glue and Step function
      id: check_status_1
      run: |
        STACK_NAME="MyGlueStepFunction"
        STACK_STATUS_1=$(aws cloudformation describe-stacks --stack-name $STACK_NAME --query "Stacks[0].StackStatus" --output text 2>&1 || echo "STACK_DOES_NOT_EXIST")
        if [[ "$STACK_STATUS_1" == "STACK_DOES_NOT_EXIST" ]]; then
          echo "Stack $STACK_NAME does not exist."
          echo "::set-output name=status_1::NOT_FOUND"
        else
          echo "Stack status for Glue and Step Function: $STACK_STATUS_1"
          echo "::set-output name=status_1::$STACK_STATUS_1"
        fi

    # - name: Delete CloudFormation stack Glue and Step function
    #   if: steps.check_status_1.outputs.status_1 != 'CREATE_COMPLETE' && steps.check_status_1.outputs.status_1 != 'NOT_FOUND'
    #   run: |
    #     echo "Deleting stack MyGlueStepFunction because status is ${{ steps.check_status_1.outputs.status_1 }}"
    #     aws cloudformation delete-stack --stack-name MyGlueStepFunction
    #     aws cloudformation wait stack-delete-complete --stack-name MyGlueStepFunction
 
    - name: Deploy Glue and Step function using CloudFormation
      if: steps.check_status_1.outputs.status_1 != 'CREATE_COMPLETE' && steps.check_status_1.outputs.status_1 != 'NOT_FOUND'
      run: |
        aws cloudformation deploy \
          --template-file cloudformation/Glue_StepFunction.yaml \
          --stack-name MyGlueStepFunction \
          --capabilities CAPABILITY_NAMED_IAM
        aws cloudformation wait stack-create-complete --stack-name MyGlueStepFunction

    - name: Check CloudFormation stack status for RDS Lambda and Secret Manager
      id: check_status_2
      run: |
        STACK_NAME="MyRdsLambdaSecretManager"
        STACK_STATUS_2=$(aws cloudformation describe-stacks --stack-name $STACK_NAME --query "Stacks[0].StackStatus" --output text 2>&1 || echo "STACK_DOES_NOT_EXIST")
        if [[ "$STACK_STATUS_2" == "STACK_DOES_NOT_EXIST" ]]; then
          echo "Stack $STACK_NAME does not exist."
          echo "::set-output name=status_2::NOT_FOUND"
        else
          echo "Stack status for RDS Lambda Secret Manager: $STACK_STATUS_2"
          echo "::set-output name=status_2::$STACK_STATUS_2"
        fi

    # - name: Delete CloudFormation stack
    #   if: steps.check_status_2.outputs.status_2 != 'CREATE_COMPLETE' && steps.check_status_2.outputs.status_2 != 'NOT_FOUND'
    #   run: |
    #     echo "Deleting stack MyRdsLambdaSecretManager because status is ${{ steps.check_status_2.outputs.status_2 }}"
    #     aws cloudformation delete-stack --stack-name MyRdsLambdaSecretManager
    #     aws cloudformation wait stack-delete-complete --stack-name MyRdsLambdaSecretManager

    - name: Create or Update RDS Secret
      if: steps.check_status_2.outputs.status_2 != 'CREATE_COMPLETE' && steps.check_status_2.outputs.status_2 != 'NOT_FOUND'
      run: |
        # Check if secret exists
        if aws secretsmanager describe-secret --secret-id ${{ secrets.SECRET_NAME }} > /dev/null 2>&1; then
           echo "Secret already exists, skipping creation..."
          # Get the existing secret's ARN
          SECRET_ARN=$(aws secretsmanager describe-secret \
          --secret-id ${{ secrets.SECRET_NAME }} \
          --query ARN --output text)
  
          echo "SECRET_ARN=$SECRET_ARN" >> $GITHUB_ENV
        else
          echo "Creating new secret..."
  
          # Generate secure password
          RDS_PASSWORD=$(openssl rand -base64 32)
  
         # Create secret JSON
         SECRET_JSON=$(jq -n \
           --arg username "postgres" \
           --arg password "$RDS_PASSWORD" \
           --arg dbname "MyDatabase" \
           --arg engine "postgres" \
           --arg host "localhost" \
           --arg port "5432" \
          '{
            "username": $username,
           "password": $password,
           "dbname": $dbname,
           "engine": $engine,
           "host": $host,
           "port": $port,
           "description": "RDS database credentials"
           }')
  
           # Create new secret
          aws secretsmanager create-secret \
            --name ${{ secrets.SECRET_NAME }} \
            --description "RDS database credentials" \
            --secret-string "$SECRET_JSON"
  
           # Get the ARN of the newly created secret
          SECRET_ARN=$(aws secretsmanager describe-secret \
            --secret-id ${{ secrets.SECRET_NAME }} \
            --query ARN --output text)
  
          echo "SECRET_ARN=$SECRET_ARN" >> $GITHUB_ENV
          echo "New secret created with ARN: $SECRET_ARN"
        fi

    - name: Verify all exports exist
      id: verify_exports
      run: |
            MAX_RETRIES=3
            RETRY_COUNT=0
            
            echo "Waiting for CloudFormation exports to be available..."
            
            while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
              # 1. Fetch all required exports
              VPC_ID=$(aws cloudformation list-exports \
                --query "Exports[?Name=='MyVPCId'].Value" \
                --output text 2>/dev/null || echo "")
              
              SUBNET_ID_1=$(aws cloudformation list-exports \
                --query "Exports[?Name=='MyPrivateSubnet1Id'].Value" \
                --output text 2>/dev/null || echo "")
                
              SUBNET_ID_2=$(aws cloudformation list-exports \
                --query "Exports[?Name=='MyPrivateSubnet2Id'].Value" \
                --output text 2>/dev/null || echo "")
              
              STATE_MACHINE_ARN=$(aws cloudformation list-exports \
                --query "Exports[?Name=='MyStateMachineArn'].Value" \
                --output text 2>/dev/null || echo "")
              
              # 2. Check if ALL required exports exist and are not "None"
              if [ -n "$VPC_ID" ] && [ "$VPC_ID" != "None" ] && \
                  [ -n "$SUBNET_ID_1" ] && [ "$SUBNET_ID_1" != "None" ] && \
                  [ -n "$SUBNET_ID_2" ] && [ "$SUBNET_ID_2" != "None" ] && \
                  [ -n "$STATE_MACHINE_ARN" ] && [ "$STATE_MACHINE_ARN" != "None" ]; then
                
                echo "✅ All required exports found!"
                echo "VPC_ID=$VPC_ID" >> $GITHUB_ENV
                echo "SUBNET_ID_1=$SUBNET_ID_1" >> $GITHUB_ENV
                echo "SUBNET_ID_2=$SUBNET_ID_2" >> $GITHUB_ENV
                echo "STATE_MACHINE_ARN=$STATE_MACHINE_ARN" >> $GITHUB_ENV
                
                exit 0
              fi
              
              # 3. Retry Logic
              RETRY_COUNT=$((RETRY_COUNT + 1))
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                echo "Some exports are missing. Retrying in 15s... ($RETRY_COUNT/$MAX_RETRIES)"
                sleep 15
              fi
            done
            
            echo "❌ ERROR: One or more required exports are missing after $MAX_RETRIES retries."
            echo "Check if the VPC and Step Function stacks were deployed successfully."
            aws cloudformation list-exports --query "Exports[*].[Name,Value]" --output table
            exit 1

    - name: Install dependencies
      run: |
          # Create the folder structure required by AWS Lambda Layers
          mkdir -p python/lib/python3.9/site-packages
          
          # Install psycopg2-binary into the folder
          # Make sure 'psycopg2-binary' is inside your requirements.txt
          pip install -r requirements.txt -t python/lib/python3.9/site-packages/

    - name: Create Zip Archive
      run: |
        # Zip the 'python' folder. 
        # The structure inside the zip must be python/lib/python3.9/...
        zip -r dependencies_package.zip python/

    
    - name: Upload to S3
      run: |
          # Uploading to your specific script bucket
          aws s3 cp dependencies_package.zip s3://scriptbucketkuangju87/dependencies_package.zip
    
    - name: Deploy Lambda and RDS using CloudFormation
      if: steps.check_status_2.outputs.status_2 != 'CREATE_COMPLETE' && steps.check_status_2.outputs.status_2 != 'NOT_FOUND'
      run: |

        # Create the zip file
        zip lambda_function.zip MyDataBucket1/lambda_stepfunction.py

        # Uploading to your specific script bucket
        aws s3 cp lambda_function.zip s3://scriptbucketkuangju87/
        
        # Then sync all files to S3
         aws s3 sync "MyDataBucket1/" s3://scriptbucketkuangju87/
        
        # Verify upload
        aws s3 ls s3://scriptbucketkuangju87/ --recursive

        # Deploy the RDS stack
        aws cloudformation deploy \
          --template-file cloudformation/RDS_Lambda_SecretManager.yaml \
          --stack-name MyRdsLambdaSecretManager \
          --parameter-overrides \
              RDSSecretArn=${{ env.SECRET_ARN }} \
              VPCId=${{ env.VPC_ID }} \
              PrivateSubnetIds="${{ env.SUBNET_ID_1 }},${{ env.SUBNET_ID_2 }}" \
              StateMachineArn=${{ env.STATE_MACHINE_ARN }} \
              DBInstanceClass=db.t3.micro  \
              DatabaseName=MyDatabase \
              TableName=UploadedData \
              DataBucket1Name=scriptbucketkuangju87 \
              DataBucket2Name=databucketkuangju87 \
          --capabilities CAPABILITY_NAMED_IAM
          

        aws cloudformation wait stack-create-complete --stack-name MyRdsLambdaSecretManager

    - name: Set S3 Trigger on Existing Bucket
      run: |
        LAMBDA_ARN=$(aws cloudformation describe-stacks --stack-name MyRdsLambdaSecretManager --query "Stacks[0].Outputs[?OutputKey=='LambdaFunctionArn'].OutputValue" --output text)
        
        # Define the notification JSON
        cat <<EOF > notification.json
        {
          "LambdaFunctionConfigurations": [
            {
              "LambdaFunctionArn": "$LAMBDA_ARN",
              "Events": ["s3:ObjectCreated:*"],
              "Filter": { "Key": { "FilterRules": [{ "Name": "suffix", "Value": ".csv" }] } }
            }
          ]
        }
        EOF

        aws s3api put-bucket-notification-configuration \
          --bucket databucketkuangju87 \
          --notification-configuration file://notification.json
